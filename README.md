# CheckEval
CheckEval: A reliable LLM-as-a-Judge framework for evaluating text generation using checklists
